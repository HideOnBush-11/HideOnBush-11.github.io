---
title: 线性回归小结
author: Ezio
data: 2020-10-14 22:27:00
categories: [machine learning]
tags: [machine learning, linear regression]
---



# 线性回归基本想法

![](https://raw.githubusercontent.com/HideOnBush-11/FigureBed/main/img/20201014224505.png)



-----

# 代价函数（cost function）

线性回归中，采用均方差来作为任务的性能指标。以下分别采用梯度下降法和正规方程的方法来求解ω和b的最优解

## 梯度下降算法（gradient descent）

![](https://raw.githubusercontent.com/HideOnBush-11/FigureBed/main/img/20201014224556.png)

![](https://raw.githubusercontent.com/HideOnBush-11/FigureBed/main/img/20201014214946.png)

### 学习率α

* 可通过画出代价函数 J(ω, b)的图像来确定多少次迭代后算法是否已经收敛

* α过小

  * 迭代次数太多，收敛较为缓慢

* α过大

  * J(ω, b)可能不会收敛（下图左上情况）

  * J(ω, b)可能在最低点的左右两边跳动，也会需要大量迭代后，才会收敛

* ![](https://raw.githubusercontent.com/HideOnBush-11/FigureBed/main/img/20201014220701.png)

------

对于α的选取，吴恩达在教程中给出一种参考。

初始化

对 0.001 ...  0.01 ...  0.1 ... 1进行划分

[0.001, 0.01]分为 [0.001 , 0.003..], [0.003.., 0.006...], [0.006.. ,0.01]这样三等分 α依次取 0.001 0.003..  0.006... 0.01这四个值

每次训练再根据J(ω,b)的图像来判断当前的学习率α是否选取适当

## 正规方程（regular expression）



![](https://raw.githubusercontent.com/HideOnBush-11/FigureBed/main/img/20201014224659.png)

![](https://raw.githubusercontent.com/HideOnBush-11/FigureBed/main/img/20201014215253.png)

## 两种算法的优缺点

| 梯度下降算法                                   | 正规方程                                                     |
| ---------------------------------------------- | ------------------------------------------------------------ |
| 需要手动选取学习率α                            | 不需要选取学习率α                                            |
| 迭代次数可能会很大，耗时比较久                 | 仅需要运行一次                                               |
| 当特征变量数目较大时，梯度下降算法通常更为有效 | 特征变量数目较大，由于算法的时间复杂度为O(n^3)，可能还比迭代更慢 |
|                                                |                                                              |

